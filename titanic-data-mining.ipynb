{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T14:09:27.270657Z","iopub.execute_input":"2021-06-11T14:09:27.271042Z","iopub.status.idle":"2021-06-11T14:09:27.286525Z","shell.execute_reply.started":"2021-06-11T14:09:27.271004Z","shell.execute_reply":"2021-06-11T14:09:27.284741Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error, precision_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\n\n#read training data file.\ndata = pd.read_csv('../input/titanic/train.csv')\n\n#Extracted features\n#Pclass because the ticket class can be an important factor\n#Sex might also be a factor\n#The lower the fare, the lower the social class, the lower the protection.\nfeatures = ['Pclass','Sex','Fare'];\n\n#mapping all males to 0, and females to 1\n#as scikit learn only handles floats\ndata.Sex = data.Sex.map({'male':0,'female':1})\n\n\n#As Kaggle wants exactly 418 entry to be in the test file\n#I used fillna to fill every NaN in Fare, with the Fare's mean without the NaNs.\ndata= data.fillna(value={'Fare':data.mean(skipna=True).Fare})\n#we can assume that all the nan values in Sex is 1 and PClass is 2\ndata= data.fillna(value={'Sex':1})\ndata= data.fillna(value={'Pclass':2})\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:09:29.569278Z","iopub.execute_input":"2021-06-11T14:09:29.569679Z","iopub.status.idle":"2021-06-11T14:09:29.595056Z","shell.execute_reply.started":"2021-06-11T14:09:29.569643Z","shell.execute_reply":"2021-06-11T14:09:29.593890Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# X (Set of features data).\nX = data[features];\n#Y (Set of target).\ny = data.Survived;\n\n#split data\ntrain_X,val_X, train_y, val_y = train_test_split(X, y, random_state=1) \n\n#create model\nmodel = RandomForestClassifier(random_state=1);\n\n#fit model\nmodel.fit(train_X,train_y);\n\n#predict primary testing values\npredictions = model.predict(val_X)\n\n#After building a Binary Classifier model, we need now to evaluate it\n#to evaluate a binary classsifer, we can use the precision and recall attributes\n#basically, precision is the classifier's ability to label true positive , not to label the false positive values.\n#recall is the ability of the classifier to find all the positive values.\nprecision = precision_score(y_pred=predictions, y_true=val_y)\n#print the precision of the classifier\nprint(precision)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:09:32.120531Z","iopub.execute_input":"2021-06-11T14:09:32.120950Z","iopub.status.idle":"2021-06-11T14:09:32.361864Z","shell.execute_reply.started":"2021-06-11T14:09:32.120916Z","shell.execute_reply":"2021-06-11T14:09:32.360787Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"0.9166666666666666\n","output_type":"stream"}]},{"cell_type":"markdown","source":"As the results say, the precision of the model is 91.6% which is nearly optimal.","metadata":{}},{"cell_type":"code","source":"#import test file\ntest_file = pd.read_csv('../input/titanic/test.csv');\n\n#Remove all the rows containing NaN in the given columns.\ntest_data = test_file.fillna(0)\n\n#map male to be 0, female to be 1\ntest_data.Sex = test_data.Sex.map({'male':0,'female':1})\n\n#prepare features.\ntest_X = test_data[features]\n\n#Predict Survival Factor of the resulting Data.\ntest_predictions = model.predict(test_X);\n\n#make a numpy array of the passenger ID pandas data.\nPID=np.array(test_data.PassengerId);\n\n#make a data frame ot export to csv.\noutput = pd.DataFrame({'PassengerId':PID,'Survived': test_predictions})\n\n#export to csv\noutput.to_csv('final.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T14:09:35.937570Z","iopub.execute_input":"2021-06-11T14:09:35.937969Z","iopub.status.idle":"2021-06-11T14:09:35.979018Z","shell.execute_reply.started":"2021-06-11T14:09:35.937933Z","shell.execute_reply":"2021-06-11T14:09:35.977996Z"},"trusted":true},"execution_count":40,"outputs":[]}]}